{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI Key  is loaded\n",
      "Langsmith Key is loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Read the file and load the keys\n",
    "token_file = open('../token.txt', 'r')\n",
    "# Read the first line\n",
    "open_ai_token_line = token_file.readline()\n",
    "\n",
    "if open_ai_token_line:\n",
    "    open_ai_key = open_ai_token_line.split('=')[1].strip()\n",
    "    print(f'Open AI Key  is loaded')\n",
    "\n",
    "# Read the second line\n",
    "langsmith_token_line = token_file.readline()\n",
    "\n",
    "if langsmith_token_line:\n",
    "    langsmith_key = langsmith_token_line.split('=')[1].strip()\n",
    "    print(f'Langsmith Key is loaded')\n",
    "\n",
    "\n",
    "if langsmith_key is not None:\n",
    "    # Configure LangSmith\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_PROJECT\"] = \"MULTI-AGENT\"\n",
    "    os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = langsmith_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    BaseMessage,\n",
    "    ChatMessage,\n",
    "    FunctionMessage,\n",
    "    HumanMessage,\n",
    ")\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.prebuilt.tool_executor import ToolExecutor, ToolInvocation\n",
    "\n",
    "\n",
    "def create_agent(llm, tools, system_message: str):\n",
    "    \"\"\"Create an agent.\"\"\"\n",
    "    functions = [convert_to_openai_function(t) for t in tools]\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a AI assistant, collaborating with other assistants.\"\n",
    "                \" Use the provided tools to progress towards defining the key elements to create a View, according to given task. \\\n",
    "                    The final response should be a JSON text that includes filters and the join rules.\"\n",
    "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "                \" will help where you left off. Execute what you can to make progress.\"\n",
    "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "    prompt = prompt.partial(system_message=system_message)\n",
    "    prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))\n",
    "    return prompt | llm.bind_functions(functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.agents import Tool\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=open_ai_key)\n",
    "\n",
    "# Read the metamodels files and create retrievel tools for each\n",
    "meta1_file = open('temp/Book.txt', 'r')\n",
    "meta2_file = open('temp/Publication.txt', 'r')\n",
    "\n",
    "documents = [{\"name\": \"Book\", \"content\": meta1_file.read()}, {\"name\": \"Publication\", \"content\": meta2_file.read()}]\n",
    "# Split documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=20, chunk_overlap=5)\n",
    "texts = text_splitter.create_documents(list(d['content'] for d in documents))\n",
    "# Select embeddings\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=open_ai_key)\n",
    "# Create a vectorstore from documents\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "# Create retriever interface\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "\n",
    "tools = []\n",
    "\n",
    "# Create QA chain inside the tools\n",
    "tools.append(\n",
    "    Tool(\n",
    "        name=documents[0][\"name\"],\n",
    "        description=f\"useful when you want to answer questions about {documents[0]['name']}\",\n",
    "        func=RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever),\n",
    "    )\n",
    ")\n",
    "tools.append(\n",
    "    Tool(\n",
    "        name=documents[1][\"name\"],\n",
    "        description=f\"useful when you want to answer questions about {documents[1]['name']}\",\n",
    "        func=RetrievalQA.from_chain_type(llm=llm, chain_type='stuff', retriever=retriever),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, Sequence, Tuple, TypedDict, Union\n",
    "\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "# This defines the object that is passed between each node\n",
    "# in the graph. We will create different nodes for each agent and tool\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    sender: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "# Helper function to create a node for a given agent\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    # We convert the agent output into a format that is suitable to append to the global state\n",
    "    if isinstance(result, FunctionMessage):\n",
    "        pass\n",
    "    else:\n",
    "        result = HumanMessage(**result.dict(exclude={\"type\", \"name\"}), name=name)\n",
    "    return {\n",
    "        \"messages\": [result],\n",
    "        # Since we have a strict workflow, we can\n",
    "        # track the sender so we know who to pass to next.\n",
    "        \"sender\": name,\n",
    "    }\n",
    "\n",
    "\n",
    "# MetaclassAnalyzer agent and node\n",
    "get_join_rules_agent = create_agent(\n",
    "    llm, \n",
    "    [tools[0], tools[1]], \n",
    "    system_message=\"You should provide which elements can be combined in the final View, according to the given task. \\\n",
    "                    In a View, the elements are combined in pairs.\\\n",
    "                    Combining two elements means that the View will include a single element representing the same domain object \\\n",
    "                    Your answer should be a list of elements.\\\n",
    "                    Each element of the list is a dictionary containing the name of this virtual relation and a tuple with the combined elements in the following format:\\\n",
    "                          {{Relation_name: (Metamodel_Identifier.Class_name, Metamodel_Identifier.Class_name)}}\\\n",
    "                    Only use class names that actually exist in the metamodels; \\\n",
    "                        don't try to invent new class names. The relation's name should combine these class names, always in camelCase.\"\n",
    ")\n",
    "get_join_rules_node = functools.partial(agent_node, agent=get_join_rules_agent, name=\"GetJoinRules\")\n",
    "\n",
    "# Filter Generator\n",
    "filter_generator_agent = create_agent(\n",
    "    llm,\n",
    "    [tools[0], tools[1]],\n",
    "    system_message=\"You should provide which elements should be selected to be present in the final View.\\\n",
    "                Your answer should be a list of elements.\\\n",
    "                Each element is in the following format: Metamodel_Identifier.Class_name.\\\n",
    "                Only use class and attribute names that actually exist in the metamodels; don't try to invent new names.\\\n",
    "                Note that frequently, the metamodels can represent the same domain, so it's possible to get some overlap between them.\\\n",
    "                This should be taken into account to avoid repeating information.\"\n",
    ")\n",
    "filter_generator_node = functools.partial(agent_node, agent=filter_generator_agent, name=\"FilterGenerator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [tools[0], tools[1]]\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "def tool_node(state):\n",
    "    \"\"\"This runs tools in the graph\n",
    "\n",
    "    It takes in an agent action and calls that tool and returns the result.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    # Based on the continue condition\n",
    "    # we know the last message involves a function call\n",
    "    last_message = messages[-1]\n",
    "    # We construct an ToolInvocation from the function_call\n",
    "    tool_input = json.loads(\n",
    "        last_message.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "    )\n",
    "    # We can pass single-arg inputs by value\n",
    "    if len(tool_input) == 1 and \"__arg1\" in tool_input:\n",
    "        tool_input = next(iter(tool_input.values()))\n",
    "    tool_name = last_message.additional_kwargs[\"function_call\"][\"name\"]\n",
    "    action = ToolInvocation(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_input,\n",
    "    )\n",
    "    # We call the tool_executor and get back a response\n",
    "    response = tool_executor.invoke(action)\n",
    "    # We use the response to create a FunctionMessage\n",
    "    function_message = FunctionMessage(\n",
    "        content=f\"{tool_name} response: {str(response)}\", name=action.tool\n",
    "    )\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [function_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either agent can decide to end\n",
    "def router(state):\n",
    "    # This is the router\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if \"function_call\" in last_message.additional_kwargs:\n",
    "        # The previus agent is invoking a tool\n",
    "        return \"call_tool\"\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        # Any agent decided the work is done\n",
    "        return \"end\"\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"GetJoinRules\", get_join_rules_node)\n",
    "workflow.add_node(\"FilterGenerator\", filter_generator_node)\n",
    "workflow.add_node(\"call_tool\", tool_node)\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"GetJoinRules\",\n",
    "    router,\n",
    "    {\"continue\": \"FilterGenerator\", \"call_tool\": \"call_tool\", \"end\": END},\n",
    ")\n",
    "workflow.add_conditional_edges(\n",
    "    \"FilterGenerator\",\n",
    "    router,\n",
    "    {\"continue\": \"GetJoinRules\", \"call_tool\": \"call_tool\", \"end\": END},\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"call_tool\",\n",
    "    # Each agent node updates the 'sender' field\n",
    "    # the tool calling node does not, meaning\n",
    "    # this edge will route back to the original agent\n",
    "    # who invoked the tool\n",
    "    lambda x: x[\"sender\"],\n",
    "    {\n",
    "        \"GetJoinRules\": \"GetJoinRules\",\n",
    "        \"FilterGenerator\": \"FilterGenerator\",\n",
    "    },\n",
    ")\n",
    "workflow.set_entry_point(\"GetJoinRules\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GetJoinRules': {'messages': [HumanMessage(content='To combine a book with a publication and get all the information in the same View, we can create a View that includes the following elements:\\n\\n1. Combine the Book model with the Publication model:\\n   - Relation name: bookPublication\\n   - Combined elements: (Book, Publication)\\n\\nHere is the final answer:\\n\\n[\\n  {\\n    \"bookPublication\": [\"Book\", \"Publication\"]\\n  }\\n]', additional_kwargs={'function_call': {'arguments': '{\\n  \"__arg1\": \"Publication\"\\n}', 'name': 'Publication'}}, name='GetJoinRules')], 'sender': 'GetJoinRules'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call_tool': {'messages': [FunctionMessage(content='Publication response: {\\'query\\': \\'Publication\\', \\'result\\': \\'The \"Publication\" class represents a generic publication, such as a book or an article. It has attributes like \"title\" (the title of the publication), \"author\" (the name of the author), \"publisher\" (the name of the publisher), and \"year\" (the year of publication).\\'}', name='Publication')]}}\n",
      "----\n",
      "{'GetJoinRules': {'messages': [HumanMessage(content='Based on the information provided, the elements that can be combined in the final View are:\\n\\n1. Combine the Book model with the Publication model:\\n   - Relation name: bookPublication\\n   - Combined elements: (Book, Publication)\\n\\n{\\n  \"bookPublication\": [\"Book\", \"Publication\"]\\n}', additional_kwargs={'function_call': {'arguments': '{\\n  \"__arg1\": \"Book\"\\n}', 'name': 'Book'}}, name='GetJoinRules')], 'sender': 'GetJoinRules'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'call_tool': {'messages': [FunctionMessage(content='Book response: {\\'query\\': \\'Book\\', \\'result\\': \\'The class diagram you provided represents a class called \"Book\". It has two attributes: \"title\" of type EString and \"authorName\" of type EString.\\'}', name='Book')]}}\n",
      "----\n",
      "{'GetJoinRules': {'messages': [HumanMessage(content='Based on the information provided, the elements that can be combined in the final View are:\\n\\n1. Combine the Book model with the Publication model:\\n   - Relation name: bookPublication\\n   - Combined elements: (Book, Publication)\\n\\nHere is the final answer:\\n\\n[\\n  {\\n    \"bookPublication\": [\"Book\", \"Publication\"]\\n  }\\n]', name='GetJoinRules')], 'sender': 'GetJoinRules'}}\n",
      "----\n",
      "{'FilterGenerator': {'messages': [HumanMessage(content='FINAL ANSWER:\\n{\\n  \"bookPublication\": [\"Book\", \"Publication\"]\\n}\\nFINAL ANSWER:\\n{\\n  \"bookPublication\": [\"Book\", \"Publication\"]\\n}', name='FilterGenerator')], 'sender': 'FilterGenerator'}}\n",
      "----\n",
      "{'__end__': {'messages': [HumanMessage(content='Since the same book being represented by a Book model or by a Publication model, the task is to define the best way to combine a book with a publication getting all the information in the same View'), HumanMessage(content='To combine a book with a publication and get all the information in the same View, we can create a View that includes the following elements:\\n\\n1. Combine the Book model with the Publication model:\\n   - Relation name: bookPublication\\n   - Combined elements: (Book, Publication)\\n\\nHere is the final answer:\\n\\n[\\n  {\\n    \"bookPublication\": [\"Book\", \"Publication\"]\\n  }\\n]', additional_kwargs={'function_call': {'arguments': '{\\n  \"__arg1\": \"Publication\"\\n}', 'name': 'Publication'}}, name='GetJoinRules'), FunctionMessage(content='Publication response: {\\'query\\': \\'Publication\\', \\'result\\': \\'The \"Publication\" class represents a generic publication, such as a book or an article. It has attributes like \"title\" (the title of the publication), \"author\" (the name of the author), \"publisher\" (the name of the publisher), and \"year\" (the year of publication).\\'}', name='Publication'), HumanMessage(content='Based on the information provided, the elements that can be combined in the final View are:\\n\\n1. Combine the Book model with the Publication model:\\n   - Relation name: bookPublication\\n   - Combined elements: (Book, Publication)\\n\\n{\\n  \"bookPublication\": [\"Book\", \"Publication\"]\\n}', additional_kwargs={'function_call': {'arguments': '{\\n  \"__arg1\": \"Book\"\\n}', 'name': 'Book'}}, name='GetJoinRules'), FunctionMessage(content='Book response: {\\'query\\': \\'Book\\', \\'result\\': \\'The class diagram you provided represents a class called \"Book\". It has two attributes: \"title\" of type EString and \"authorName\" of type EString.\\'}', name='Book'), HumanMessage(content='Based on the information provided, the elements that can be combined in the final View are:\\n\\n1. Combine the Book model with the Publication model:\\n   - Relation name: bookPublication\\n   - Combined elements: (Book, Publication)\\n\\nHere is the final answer:\\n\\n[\\n  {\\n    \"bookPublication\": [\"Book\", \"Publication\"]\\n  }\\n]', name='GetJoinRules'), HumanMessage(content='FINAL ANSWER:\\n{\\n  \"bookPublication\": [\"Book\", \"Publication\"]\\n}\\nFINAL ANSWER:\\n{\\n  \"bookPublication\": [\"Book\", \"Publication\"]\\n}', name='FilterGenerator')], 'sender': 'FilterGenerator'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"Since the same book being represented by a Book model or by a Publication model, the task is to define the best way to combine a book with a publication getting all the information in the same View\"\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "    # Maximum number of steps to take in the graph\n",
    "    {\"recursion_limit\": 100},\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
